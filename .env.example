# LLM Configuration
LLAMA_MODEL_PATH=./data/models/llama-2-7b-chat.Q4_K_M.gguf
MODEL_N_CTX=4096
MODEL_N_GPU_LAYERS=0  # Set to number of layers to offload to GPU

# Vector Database
CHROMA_PERSIST_DIRECTORY=./data/vectordb
COLLECTION_NAME=documenter

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Document Sources
LANGCHAIN_DOCS_URL=https://python.langchain.com/docs/
FASTAPI_DOCS_URL=https://fastapi.tiangolo.com/

# API Keys (if using external services)
GEMINI_API_KEY= AIzaSyA0BUQZki2aVi4iADHMk-WtWpiGHqJ8pEY 

# Monitoring
LOG_LEVEL=INFO
ENABLE_MONITORING=true
